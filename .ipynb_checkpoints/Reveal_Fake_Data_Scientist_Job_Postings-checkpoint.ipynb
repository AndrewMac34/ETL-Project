{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_jobs_pd = pd.read_csv(\"data_source/fake_job_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Account Executive - Washington DC</td>\n",
       "      <td>US, DC, Washington</td>\n",
       "      <td>Sales</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n",
       "      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n",
       "      <td>Our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bill Review Manager</td>\n",
       "      <td>US, FL, Fort Worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n",
       "      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n",
       "      <td>Full Benefits Offered</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title            location  \\\n",
       "0       1                           Marketing Intern    US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n",
       "3       4          Account Executive - Washington DC  US, DC, Washington   \n",
       "4       5                        Bill Review Manager  US, FL, Fort Worth   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "3      Sales          NaN  Our passion for improving quality of life thro...   \n",
       "4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "3  THE COMPANY: ESRI – Environmental Systems Rese...   \n",
       "4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
       "4  QUALIFICATIONS:RN license in the State of Texa...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "3  Our culture is anything but corporate—we have ...              0   \n",
       "4                              Full Benefits Offered              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "3                 1              0       Full-time    Mid-Senior level   \n",
       "4                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "  required_education                   industry              function  \\\n",
       "0                NaN                        NaN             Marketing   \n",
       "1                NaN  Marketing and Advertising      Customer Service   \n",
       "2                NaN                        NaN                   NaN   \n",
       "3  Bachelor's Degree          Computer Software                 Sales   \n",
       "4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "\n",
       "   fraudulent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_jobs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_jobs_pd = pd.read_csv(\"data_source/data_scientist_united_states_job_postings_jobspikr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_jobs_pd.head()\n",
    "len(ds_jobs_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only Fraud records\n",
    "#fake_jobs = pd.DataFrame([\"fraudulent\"],index = [\"fraudulent\"], columns=[\"fraudulent\"])\n",
    "if fake_jobs_pd.index.name != 'fraudulent':\n",
    "   fake_jobs_pd.set_index(\"fraudulent\", inplace = True)\n",
    "fake_jobs = fake_jobs_pd.loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15547\n"
     ]
    }
   ],
   "source": [
    "#Create dict to collect word count\n",
    "word_count = {}\n",
    "#Count words in fake job postings\n",
    "for description in fake_jobs['description']:\n",
    " for word in str(description).split():\n",
    "    if word_count.get(word, 0) != 0:\n",
    "         word_count[word] += 1  \n",
    "#         print(word_count[word])\n",
    "    else:\n",
    "         word_count[word] = 1\n",
    "#         print(word_count[word])\n",
    "\n",
    "\n",
    "#Create dataframe\n",
    "data_items = sorted(word_count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "data_list = list(data_items)\n",
    "word_count_pd = pd.DataFrame(data_list,columns=[\"word\",\"counter\"])\n",
    "print(len(word_count_pd))\n",
    "#Limit size of words to analyze\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'][:].str.len() < 4].index, inplace = True)\n",
    "#drop prepositions and other not significant words\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'with'].index, inplace = True) \n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'that'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'from'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'have'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'your'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'this'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'their'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == '&amp;'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'will'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'This'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'more'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'into'].index, inplace = True)\n",
    "word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'also'].index, inplace = True)\n",
    "#word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'other'].index, inplace = True)\n",
    "word_count_pd.to_csv(\"words_in_fake_posting.csv\")\n",
    "\n",
    "#word_count_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only Real Posting records\n",
    "if fake_jobs_pd.index.name != 'fraudulent':\n",
    "   fake_jobs_pd.set_index(\"fraudulent\", inplace = True)\n",
    "real_jobs_pd = fake_jobs_pd.loc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dict to collect word count for real job postings\n",
    "word_count_real = {}\n",
    "#Count words in fake job postings\n",
    "for description in real_jobs_pd['description']:\n",
    " for word in str(description).split():\n",
    "    if word_count_real.get(word, 0) != 0:\n",
    "         word_count_real[word] += 1  \n",
    "    else:\n",
    "         word_count_real[word] = 1\n",
    "\n",
    "#Create dataframe\n",
    "data_items = sorted(word_count_real.items(), key=lambda kv: kv[1], reverse=True)\n",
    "data_list = list(data_items)\n",
    "word_count_real_pd = pd.DataFrame(data_list,columns=[\"word\",\"counter\"])\n",
    "#Limit size of words to analyze\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'][:].str.len() < 4].index, inplace = True)\n",
    "#drop prepositions and other not significant words\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'with'].index, inplace = True) \n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'that'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'from'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'have'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'your'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'this'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'their'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == '&amp;'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'will'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'This'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'more'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'into'].index, inplace = True)\n",
    "word_count_real_pd.drop(word_count_real_pd[word_count_real_pd['word'] == 'also'].index, inplace = True)\n",
    "#word_count_pd.drop(word_count_pd[word_count_pd['word'] == 'other'].index, inplace = True)\n",
    "type(word_count_real_pd)\n",
    "#word_count_real_pd.to_csv(\"words_in_real_posting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fake_words_to_check = word_count_pd.merge(word_count_real_pd, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\n",
    "fake_words_to_check= fake_words_to_check[0:50]\n",
    "fake_words_to_check['weight']=fake_words_to_check['counter']/fake_words_to_check['counter'].sum()\n",
    "fake_words_to_check.head()\n",
    "fake_words_to_check.set_index = [\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named Read for object type <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-040790d0e144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'work'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"karaka\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m      \u001b[1;32mif\u001b[0m \u001b[0mfake_words_to_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m          \u001b[1;31m#perc_fake[word] += fake_words_to_check['weight']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         \u001b[0mnew_self\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No axis named {axis} for object type {cls}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No axis named Read for object type <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "#Check possible fake job postings in the Data Science file\n",
    "#The idea is to sum the % of fake_words_to_check in the description.\n",
    "#The posting will be considered fake if the sum is over 0.5%\n",
    "#perc_fake= pd.DataFrame([\"Job_title\",'city', 'state', 'country',\n",
    "#                                     'Category','Job_description','job_type'])\n",
    "perc_fake= pd.DataFrame([\"Word\"])\n",
    "\n",
    "#fake_words_to_check = {}\n",
    "#Count words in Data Science job postings\n",
    "for description in ds_jobs_pd['job_description']:\n",
    " for word in str(description).split():\n",
    "     if word == 'work':\n",
    "        print(f\"karaka\",word)\n",
    "     if fake_words_to_check.loc(word):\n",
    "\n",
    "         #perc_fake[word] += fake_words_to_check['weight']\n",
    "         #perc_fake[word] = \"bla\"\n",
    "           print(word)\n",
    "            \n",
    "#     print(f\"sdfdsf \", perc_fake, fake_words_to_check.get(word,0),word)\n",
    "\n",
    "\n",
    "#df.loc[df['column_name'] == some_value]\n",
    " #if perc_fake[word] > 0.5:\n",
    " #       ds_fake_jobs_pd = ds_jobs_pd[\"Job_title\",'city', 'state', 'country',\n",
    " #                                    'Category','Job_description','job_type']\n",
    "                                     \n",
    "\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perc_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python37664bitpythondataconda11c2940b2c864458be665c9a14ae3ee3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
